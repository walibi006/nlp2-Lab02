{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP LAB 2 - Encoder-decoder model\n",
    "\n",
    "Authors:\n",
    "* Aurelien ROUXEL\n",
    "* Ethan MACHAVOINE\n",
    "* Jonathan POELGER"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "from typing import Iterable, List\n",
    "\n",
    "\n",
    "# We need to modify the URLs for the dataset since the links to the original dataset are broken\n",
    "# Refer to https://github.com/pytorch/text/issues/1756#issuecomment-1163664163 for more info\n",
    "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
    "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
    "\n",
    "SRC_LANGUAGE = 'de'\n",
    "TGT_LANGUAGE = 'en'\n",
    "\n",
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 18:27:01.491522: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-22 18:27:03.069388: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-22 18:27:03.074338: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-22 18:27:03.074597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "\n",
    "# helper function to yield list of tokens\n",
    "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language_index[language]])\n",
    "\n",
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['< unk >', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    # Training data Iterator\n",
    "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    # Create torchtext's Vocab object\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
    "                                                    min_freq=1,\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True)\n",
    "\n",
    "# Set ``UNK_IDX`` as the default index. This index is returned when the token is not found.\n",
    "# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "  vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Seq2Seq Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "                                               vocab_transform[ln], #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# function to collate data samples into batch tensors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    for src, tgt in train_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(train_dataloader))\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    for src, tgt in val_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ethan/.local/lib/python3.10/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "/home/ethan/.local/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/combining.py:297: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 5.343, Val loss: 4.113, Epoch time = 43.071s\n",
      "Epoch: 2, Train loss: 3.762, Val loss: 3.323, Epoch time = 42.175s\n",
      "Epoch: 3, Train loss: 3.158, Val loss: 2.891, Epoch time = 42.501s\n",
      "Epoch: 4, Train loss: 2.767, Val loss: 2.633, Epoch time = 42.569s\n",
      "Epoch: 5, Train loss: 2.480, Val loss: 2.444, Epoch time = 42.618s\n",
      "Epoch: 6, Train loss: 2.247, Val loss: 2.303, Epoch time = 42.641s\n",
      "Epoch: 7, Train loss: 2.054, Val loss: 2.201, Epoch time = 42.794s\n",
      "Epoch: 8, Train loss: 1.894, Val loss: 2.116, Epoch time = 42.846s\n",
      "Epoch: 9, Train loss: 1.754, Val loss: 2.055, Epoch time = 43.865s\n",
      "Epoch: 10, Train loss: 1.630, Val loss: 1.995, Epoch time = 43.958s\n",
      "Epoch: 11, Train loss: 1.520, Val loss: 1.961, Epoch time = 44.006s\n",
      "Epoch: 12, Train loss: 1.419, Val loss: 1.948, Epoch time = 43.913s\n",
      "Epoch: 13, Train loss: 1.334, Val loss: 1.956, Epoch time = 44.014s\n",
      "Epoch: 14, Train loss: 1.252, Val loss: 1.953, Epoch time = 43.750s\n",
      "Epoch: 15, Train loss: 1.171, Val loss: 1.939, Epoch time = 44.050s\n",
      "Epoch: 16, Train loss: 1.101, Val loss: 1.933, Epoch time = 43.450s\n",
      "Epoch: 17, Train loss: 1.035, Val loss: 1.912, Epoch time = 43.235s\n",
      "Epoch: 18, Train loss: 0.974, Val loss: 1.916, Epoch time = 43.433s\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 18\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "\n",
    "\n",
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A group of people stand in an auditorium . \n"
     ]
    }
   ],
   "source": [
    "print(translate(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:\n",
    "* A group of people stand in an auditorium ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Theoretical questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the positional encoding, why are we using a combination of sinus and cosinus ?\n",
    "\n",
    " * The combination of sinus and cosinus functions in the positional encodings is used to ensures that the positional information is represented in a continuous and smooth manner. This allows the model to generalize well to sequences of different lengths and enables the model to learn token positions better."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the Seq2SeqTransformer class, what is the parameter nhead for ?\n",
    " \n",
    " * The nhead parameter in the Seq2SeqTransformer class corresponds to the number of attention heads in the Transformer model. Each attention head will learn to focus on different aspects of the input sequence, attending to different positions and learning different relationships."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the Seq2SeqTransformer class, what is the point of the generator ?\n",
    "\n",
    " * The purpose of the generator layer is to transform the hidden states into a probability distribution over the target vocabulary. Each element of the output tensor represents the likelihood of the corresponding word in the vocabulary being the next word in the output sequence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe the goal of the `create_mask` function. Why does it handle differently the source and target masks ?\n",
    "\n",
    "* The create_mask function is responsible for creating masks that indicate in the input sequence and in the output sequence which positions should be attended to and which positions should be ignored during the self-attention calculation in the Transformer model. The goal of the create_mask function is to ensure that the model attends only to the relevant positions and prevents attending to future positions during training and prediction. It handles the source and the target differently because:\n",
    "    * The source mask is used to prevent the model from attending to the padding tokens in the input sequence.\n",
    "    * The target mask is used in both the encoder and decoder parts of the Transformer. In the encoder, it serves the same purpose as the source mask but, in the decoder, the target mask has an additional role, which is to prevent attending to future positions during training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decoding functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top-k sampling with temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_decode(model, src, src_mask, max_len, start_symbol, top_k = 1, temperature = 1.0):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out[-1, :] / temperature\n",
    "        filtered_logits, indices = torch.topk(out, top_k, dim=-1)\n",
    "        probabilities = torch.nn.functional.softmax(filtered_logits, dim=-1)\n",
    "        next_word = torch.multinomial(probabilities, num_samples=1).item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_topk(model: torch.nn.Module, src_sentence: str, topk, temperature):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = top_k_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX, top_k = topk, temperature = temperature).flatten()\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " an woman . black at . boy blue a  of <unk> \n"
     ]
    }
   ],
   "source": [
    "print(translate_topk(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\", 40, 0.8))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:\n",
    "*    an woman . black at . boy blue a  of $< unk >$ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top-p sampling with temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_p_decode(model, src, src_mask, max_len, start_symbol, top_p = 1, temperature = 1.0):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out[-1, :] / temperature\n",
    "        sorted_probs, sorted_indices = torch.sort(out, descending=True)\n",
    "        cumulative_probs = torch.cumsum(torch.nn.functional.softmax(sorted_probs, dim=-1), dim=-1)\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        sorted_indices_to_remove[:, 1:] = sorted_indices_to_remove[:, :-1].clone()\n",
    "        sorted_indices_to_remove[:, 0] = 0\n",
    "        indices_to_remove = sorted_indices_to_remove.scatter(dim=1, index=sorted_indices, src=sorted_indices_to_remove)\n",
    "        out[indices_to_remove] = float('-inf')\n",
    "        out = torch.nn.functional.softmax(out, dim=-1)\n",
    "        next_word = torch.multinomial(out, num_samples=1).item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_topp(model: torch.nn.Module, src_sentence: str, topp, temperature):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = top_p_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX, top_p = topp, temperature = temperature).flatten()\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " brick women it hands sign helmet watching sweatshirt all climbing workers young a food workers\n"
     ]
    }
   ],
   "source": [
    "print(translate_topp(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\", 0.6, 0.8))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:\n",
    "* brick women it hands sign helmet watching sweatshirt all climbing workers young a food workers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Play with the k, p and temperature parameters, and compare a few translation samples for each approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-K: 10 Top-P: 0.3 Temperature: 0.5\n",
      "Sentence: Wie lange lebst du schon in Stuttgart ?\n",
      "Translation Top-K:   <unk> .  <pad> <unk> <pad> . on A A <pad>  <unk>\n",
      "Translation Top-P:  arm very run Men fire fire stone left Men adult fire fire fire fire\n",
      "Translation Greedy:  Large long - haired great Dane can be using matching factory ? \n",
      "True Translation: How long have you been living in Stuttgart?\n",
      "\n",
      "Sentence: Eine Gruppe von Menschen steht vor einem Iglu .\n",
      "Translation Top-K:  . the <unk> <unk> <unk> <unk> <pad> \n",
      "Translation Top-P:  putting gray gray gray gray gray gray photo photo between down down down down down\n",
      "Translation Greedy:  A group of people stand in an auditorium . \n",
      "True Translation: A group of people standing in front of an igloo .\n",
      "\n",
      "Sentence: Möglichst ganze Wörter eingeben, die im Artikeltext, insbesondere aber im Lemma vorkommen sollen. \n",
      "Translation Top-K:  a a <pad>  on <unk> in <unk> .  <pad>  on on A <unk> A <pad>  a <pad> \n",
      "Translation Top-P:  fishing cross cross both playing both playing African eating full cross does does does sand does does sand their crowded climbing while\n",
      "Translation Greedy:  A female snow athlete with matching belt , who is crouched together in the snowy moment . \n",
      "True Translation: If possible, enter whole words that should appear in the article text, but especially in the lemma.\n",
      "\n",
      "Top-K: 20 Top-P: 0.5 Temperature: 0.5\n",
      "Sentence: Wie lange lebst du schon in Stuttgart ?\n",
      "Translation Top-K:  a <pad> <unk> <unk> <pad> in <unk> \n",
      "Translation Top-P:  head old court crowd cross leaning leaning floor Men floor Men climbing climbing while\n",
      "Translation Greedy:  Large long - haired great Dane can be using matching factory ? \n",
      "True Translation: How long have you been living in Stuttgart?\n",
      "\n",
      "Sentence: Eine Gruppe von Menschen steht vor einem Iglu .\n",
      "Translation Top-K:  <pad> <pad> <unk> <unk>  <pad>  on \n",
      "Translation Top-P:  sign cart cart cart cart smiling climbing smiling climbing An climbing climbing climbing An down\n",
      "Translation Greedy:  A group of people stand in an auditorium . \n",
      "True Translation: A group of people standing in front of an igloo .\n",
      "\n",
      "Sentence: Möglichst ganze Wörter eingeben, die im Artikeltext, insbesondere aber im Lemma vorkommen sollen. \n",
      "Translation Top-K:  woman A <pad> on man <pad> \n",
      "Translation Top-P:  fishing cross old African both stage fire fire watching fire fire fire cowboy fire men men fire fire climbing stage stage their\n",
      "Translation Greedy:  A female snow athlete with matching belt , who is crouched together in the snowy moment . \n",
      "True Translation: If possible, enter whole words that should appear in the article text, but especially in the lemma.\n",
      "\n",
      "Top-K: 40 Top-P: 0.7 Temperature: 0.5\n",
      "Sentence: Wie lange lebst du schon in Stuttgart ?\n",
      "Translation Top-K:  and <unk> with <unk> shirt <pad>  A people . <unk> girl , <unk>\n",
      "Translation Top-P:  volleyball hat old women fire front Men computer fire while floor fire fire football\n",
      "Translation Greedy:  Large long - haired great Dane can be using matching factory ? \n",
      "True Translation: How long have you been living in Stuttgart?\n",
      "\n",
      "Sentence: Eine Gruppe von Menschen steht vor einem Iglu .\n",
      "Translation Top-K:  white . in <pad> <unk> white girl <pad> his <pad> <unk> <pad> the are ,\n",
      "Translation Top-P:  wave cart cart cart gray smiling smiling cart left climbing down climbing climbing down climbing\n",
      "Translation Greedy:  A group of people stand in an auditorium . \n",
      "True Translation: A group of people standing in front of an igloo .\n",
      "\n",
      "Sentence: Möglichst ganze Wörter eingeben, die im Artikeltext, insbesondere aber im Lemma vorkommen sollen. \n",
      "Translation Top-K:  <unk> in is <unk> is to  are  \n",
      "Translation Top-P:  fishing cross old both full cross both water stage pushing stage fire fire men dog men men fire men climbing both while\n",
      "Translation Greedy:  A female snow athlete with matching belt , who is crouched together in the snowy moment . \n",
      "True Translation: If possible, enter whole words that should appear in the article text, but especially in the lemma.\n",
      "\n",
      "Top-K: 10 Top-P: 0.3 Temperature: 0.8\n",
      "Sentence: Wie lange lebst du schon in Stuttgart ?\n",
      "Translation Top-K:  <unk> <pad> . in A <pad> in <unk> \n",
      "Translation Top-P:  running old court rocks fire football Men fire floor fire fire fire fire while\n",
      "Translation Greedy:  Large long - haired great Dane can be using matching factory ? \n",
      "True Translation: How long have you been living in Stuttgart?\n",
      "\n",
      "Sentence: Eine Gruppe von Menschen steht vor einem Iglu .\n",
      "Translation Top-K:   the <pad> <unk> A <unk> \n",
      "Translation Top-P:  posing drink climbing working ready An working smiling climbing climbing workers between climbing while climbing\n",
      "Translation Greedy:  A group of people stand in an auditorium . \n",
      "True Translation: A group of people standing in front of an igloo .\n",
      "\n",
      "Sentence: Möglichst ganze Wörter eingeben, die im Artikeltext, insbesondere aber im Lemma vorkommen sollen. \n",
      "Translation Top-K:  <unk> <unk> <pad> \n",
      "Translation Top-P:  fishing cross leaning fence front have scarf stage crowded arms left fire fire watching their day stage climbing their appears men climbing\n",
      "Translation Greedy:  A female snow athlete with matching belt , who is crouched together in the snowy moment . \n",
      "True Translation: If possible, enter whole words that should appear in the article text, but especially in the lemma.\n",
      "\n",
      "Top-K: 20 Top-P: 0.5 Temperature: 0.8\n",
      "Sentence: Wie lange lebst du schon in Stuttgart ?\n",
      "Translation Top-K:  <unk> A and are the <pad> is man woman <unk> on <pad> of \n",
      "Translation Top-P:  car full floor - face computer motorcycle hat motorcycle aged full talking aged lined\n",
      "Translation Greedy:  Large long - haired great Dane can be using matching factory ? \n",
      "True Translation: How long have you been living in Stuttgart?\n",
      "\n",
      "Sentence: Eine Gruppe von Menschen steht vor einem Iglu .\n",
      "Translation Top-K:  woman \n",
      "Translation Top-P:  ramp who bridge Man Many wave between smiling Men short men soccer woods helmet short\n",
      "Translation Greedy:  A group of people stand in an auditorium . \n",
      "True Translation: A group of people standing in front of an igloo .\n",
      "\n",
      "Sentence: Möglichst ganze Wörter eingeben, die im Artikeltext, insbesondere aber im Lemma vorkommen sollen. \n",
      "Translation Top-K:  are and in  man Two <unk> the to man <pad> . Two the <pad> man <unk> woman of  <unk> <pad>\n",
      "Translation Top-P:  where leaning cross its glasses others baseball crowded sky fire on fish leaning green crowded walks subway while tall bus adult jumping\n",
      "Translation Greedy:  A female snow athlete with matching belt , who is crouched together in the snowy moment . \n",
      "True Translation: If possible, enter whole words that should appear in the article text, but especially in the lemma.\n",
      "\n",
      "Top-K: 40 Top-P: 0.7 Temperature: 0.8\n",
      "Sentence: Wie lange lebst du schon in Stuttgart ?\n",
      "Translation Top-K:  <pad> is man his <unk> black man men at of \n",
      "Translation Top-P:  jersey cross glasses leaning motorcycle Men Men jeans while instrument while colorful Men Men\n",
      "Translation Greedy:  Large long - haired great Dane can be using matching factory ? \n",
      "True Translation: How long have you been living in Stuttgart?\n",
      "\n",
      "Sentence: Eine Gruppe von Menschen steht vor einem Iglu .\n",
      "Translation Top-K:  , shirt girl Two white on <unk> people shirt <pad> young the <unk> \n",
      "Translation Top-P:  posing who over down left climbing he snowy down down stairs orange down fire several\n",
      "Translation Greedy:  A group of people stand in an auditorium . \n",
      "True Translation: A group of people standing in front of an igloo .\n",
      "\n",
      "Sentence: Möglichst ganze Wörter eingeben, die im Artikeltext, insbesondere aber im Lemma vorkommen sollen. \n",
      "Translation Top-K:  <pad> at <unk> young of at  black , blue woman and the of  \n",
      "Translation Top-P:  trying stage stage colorful shirts waiting tan playing jump skateboard bench background between she dog men attire while performs basketball crowded climbing\n",
      "Translation Greedy:  A female snow athlete with matching belt , who is crouched together in the snowy moment . \n",
      "True Translation: If possible, enter whole words that should appear in the article text, but especially in the lemma.\n",
      "\n",
      "Top-K: 10 Top-P: 0.3 Temperature: 1.2\n",
      "Sentence: Wie lange lebst du schon in Stuttgart ?\n",
      "Translation Top-K:  <unk> . \n",
      "Translation Top-P:  fishing African rocks leaning colorful other court hat piece Men climbing fire climbing while\n",
      "Translation Greedy:  Large long - haired great Dane can be using matching factory ? \n",
      "True Translation: How long have you been living in Stuttgart?\n",
      "\n",
      "Sentence: Eine Gruppe von Menschen steht vor einem Iglu .\n",
      "Translation Top-K:  <pad> <pad> <pad> <pad> \n",
      "Translation Top-P:  putting cart toward family sidewalk Man gray gray food climbing sweatshirt paper riding Children window\n",
      "Translation Greedy:  A group of people stand in an auditorium . \n",
      "True Translation: A group of people standing in front of an igloo .\n",
      "\n",
      "Sentence: Möglichst ganze Wörter eingeben, die im Artikeltext, insbesondere aber im Lemma vorkommen sollen. \n",
      "Translation Top-K:   in a <unk> <unk> the the . A  A <pad> A the <unk> <unk> . <pad> <pad> a <unk> \n",
      "Translation Top-P:  edge shoes fire motorcycle scarf pants cross People cellphone on attire watching both scarf their couple green men men between catch An\n",
      "Translation Greedy:  A female snow athlete with matching belt , who is crouched together in the snowy moment . \n",
      "True Translation: If possible, enter whole words that should appear in the article text, but especially in the lemma.\n",
      "\n",
      "Top-K: 20 Top-P: 0.5 Temperature: 1.2\n",
      "Sentence: Wie lange lebst du schon in Stuttgart ?\n",
      "Translation Top-K:  <unk> . <pad> to the . A <unk> <unk> <unk> <pad> of <unk> the\n",
      "Translation Top-P:  head cross old band line event backpack between stone aged leaning while - paper\n",
      "Translation Greedy:  Large long - haired great Dane can be using matching factory ? \n",
      "True Translation: How long have you been living in Stuttgart?\n",
      "\n",
      "Sentence: Eine Gruppe von Menschen steht vor einem Iglu .\n",
      "Translation Top-K:  are , are a a of to a  the a Two \n",
      "Translation Top-P:  left sign going going between enjoying suit smiling smiling Men he event left Men while\n",
      "Translation Greedy:  A group of people stand in an auditorium . \n",
      "True Translation: A group of people standing in front of an igloo .\n",
      "\n",
      "Sentence: Möglichst ganze Wörter eingeben, die im Artikeltext, insbesondere aber im Lemma vorkommen sollen. \n",
      "Translation Top-K:  \n",
      "Translation Top-P:  yard run tree setting does playing table cross dog drinking full colorful jersey This while stage at filled football African African cap\n",
      "Translation Greedy:  A female snow athlete with matching belt , who is crouched together in the snowy moment . \n",
      "True Translation: If possible, enter whole words that should appear in the article text, but especially in the lemma.\n",
      "\n",
      "Top-K: 40 Top-P: 0.7 Temperature: 1.2\n",
      "Sentence: Wie lange lebst du schon in Stuttgart ?\n",
      "Translation Top-K:  are .  sitting and A woman man young of standing at boy a\n",
      "Translation Top-P:  inside fishing worker fishing making music leaning outdoor other leaning like elderly hat blue\n",
      "Translation Greedy:  Large long - haired great Dane can be using matching factory ? \n",
      "True Translation: How long have you been living in Stuttgart?\n",
      "\n",
      "Sentence: Eine Gruppe von Menschen steht vor einem Iglu .\n",
      "Translation Top-K:  sitting man wearing  his <pad> of at <pad> of black the at in black\n",
      "Translation Top-P:  building gray hats person doing where floor something This tank camera <unk> orange ground construction\n",
      "Translation Greedy:  A group of people stand in an auditorium . \n",
      "True Translation: A group of people standing in front of an igloo .\n",
      "\n",
      "Sentence: Möglichst ganze Wörter eingeben, die im Artikeltext, insbesondere aber im Lemma vorkommen sollen. \n",
      "Translation Top-K:  his . blue A man dog shirt boy <pad> \n",
      "Translation Top-P:  driving hands run stage \" outfit their tree track stone both poses fire crowded does takes baby basketball cutting fence tall elderly\n",
      "Translation Greedy:  A female snow athlete with matching belt , who is crouched together in the snowy moment . \n",
      "True Translation: If possible, enter whole words that should appear in the article text, but especially in the lemma.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters_k = [10, 20, 40]\n",
    "parameters_p = [0.3, 0.5, 0.7]\n",
    "parameters_temp = [0.5, 0.8, 1.2]\n",
    "sentences = [\"Wie lange lebst du schon in Stuttgart ?\", \"Eine Gruppe von Menschen steht vor einem Iglu .\", \"Möglichst ganze Wörter eingeben, die im Artikeltext, insbesondere aber im Lemma vorkommen sollen. \"]\n",
    "translations = [\"How long have you been living in Stuttgart?\", \"A group of people standing in front of an igloo .\", \"If possible, enter whole words that should appear in the article text, but especially in the lemma.\"]\n",
    "for temp in parameters_temp:\n",
    "    for k, p in zip(parameters_k, parameters_p):\n",
    "        print(\"Top-K: \" + str(k) + \" Top-P: \" + str(p) + \" Temperature: \" + str(temp))\n",
    "        for sentence, translation in zip(sentences, translations):\n",
    "            print(\"Sentence: \" + sentence)\n",
    "            print(\"Translation Top-K: \" + translate_topk(transformer, sentence, k, temp))\n",
    "            print(\"Translation Top-P: \" + translate_topp(transformer, sentence, p, temp))\n",
    "            print(\"Translation Greedy: \" + translate(transformer, sentence))\n",
    "            print(\"True Translation: \" + translation)\n",
    "            print(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:\n",
    "\n",
    "Top-K: 10 Top-P: 0.3 Temperature: 0.5\n",
    "* Sentence: Wie lange lebst du schon in Stuttgart ?\n",
    "    \n",
    "    * Translation Top-K:   < unk > .  < pad > < unk >  < pad > . on A A < pad >  < unk >\n",
    "    * Translation Top-P:  arm very run Men fire fire stone left Men adult fire fire fire fire\n",
    "    * Translation Greedy:  Large long - haired great Dane can be using matching factory ? \n",
    "    * True Translation: How long have you been living in Stuttgart?\n",
    "\n",
    "\n",
    "* Sentence: Eine Gruppe von Menschen steht vor einem Iglu .\n",
    "    \n",
    "    * Translation Top-K:  . the < unk > < unk > < unk > < unk > < pad > \n",
    "    * Translation Top-P:  putting gray gray gray gray gray gray photo photo between down down down down down\n",
    "    * Translation Greedy:  A group of people stand in an auditorium . \n",
    "    * True Translation: A group of people standing in front of an igloo .\n",
    "\n",
    "\n",
    "* Sentence: Möglichst ganze Wörter eingeben, die im Artikeltext, insbesondere aber im Lemma vorkommen sollen. \n",
    "    \n",
    "    * Translation Top-K:  a a < pad >  on < unk > in < unk > .  < pad >  on on A < unk > A < pad >  a < pad > \n",
    "    * Translation Top-P:  fishing cross cross both playing both playing African eating full cross does does does sand does does sand their crowded climbing while\n",
    "    * Translation Greedy:  A female snow athlete with matching belt , who is crouched together in the snowy moment . \n",
    "    * True Translation: If possible, enter whole words that should appear in the article text, but especially in the lemma.\n",
    "\n",
    "\n",
    "Top-K: 20 Top-P: 0.5 Temperature: 0.5\n",
    "* Sentence: Wie lange lebst du schon in Stuttgart ?\n",
    "    \n",
    "    * Translation Top-K:  a < pad > < unk > < unk > < pad > in < unk > \n",
    "    * Translation Top-P:  head old court crowd cross leaning leaning floor Men floor Men climbing climbing while\n",
    "    * Translation Greedy:  Large long - haired great Dane can be using matching factory ? \n",
    "    * True Translation: How long have you been living in Stuttgart?\n",
    "\n",
    "\n",
    "* Sentence: Eine Gruppe von Menschen steht vor einem Iglu .\n",
    "    \n",
    "    * Translation Top-K:  < pad > < pad > < unk > < unk >  < pad >  on \n",
    "    * Translation Top-P:  sign cart cart cart cart smiling climbing smiling climbing An climbing climbing climbing An down\n",
    "    * Translation Greedy:  A group of people stand in an auditorium . \n",
    "    * True Translation: A group of people standing in front of an igloo .\n",
    "\n",
    "\n",
    "* Sentence: Möglichst ganze Wörter eingeben, die im Artikeltext, insbesondere aber im Lemma vorkommen sollen. \n",
    "    \n",
    "    * Translation Top-K:  woman A < pad > on man < pad > \n",
    "    * Translation Top-P:  fishing cross old African both stage fire fire watching fire fire fire cowboy fire men men fire fire climbing stage stage their\n",
    "    * Translation Greedy:  A female snow athlete with matching belt , who is crouched together in the snowy moment . \n",
    "    * True Translation: If possible, enter whole words that should appear in the article text, but especially in the lemma.\n",
    "\n",
    "\n",
    "Top-K: 40 Top-P: 0.7 Temperature: 0.5\n",
    "* Sentence: Wie lange lebst du schon in Stuttgart ?\n",
    "    \n",
    "    * Translation Top-K:  and < unk > with < unk > shirt < pad >  A people . < unk > girl , < unk >\n",
    "    * Translation Top-P:  volleyball hat old women fire front Men computer fire while floor fire fire football\n",
    "    * Translation Greedy:  Large long - haired great Dane can be using matching factory ? \n",
    "    * True Translation: How long have you been living in Stuttgart?\n",
    "\n",
    "\n",
    "* Sentence: Eine Gruppe von Menschen steht vor einem Iglu .\n",
    "    \n",
    "    * Translation Top-K:  white . in < pad > < unk > white girl < pad > his < pad > < unk > < pad > the are ,\n",
    "    * Translation Top-P:  wave cart cart cart gray smiling smiling cart left climbing down climbing climbing down climbing\n",
    "    * Translation Greedy:  A group of people stand in an auditorium . \n",
    "    * True Translation: A group of people standing in front of an igloo .\n",
    "\n",
    "\n",
    "* Sentence: Möglichst ganze Wörter eingeben, die im Artikeltext, insbesondere aber im Lemma vorkommen sollen. \n",
    "    \n",
    "    * Translation Top-K:  < unk > in is < unk > is to  are  \n",
    "    * Translation Top-P:  fishing cross old both full cross both water stage pushing stage fire fire men dog men men fire men climbing both while\n",
    "    * Translation Greedy:  A female snow athlete with matching belt , who is crouched together in the snowy moment . \n",
    "    * True Translation: If possible, enter whole words that should appear in the article text, but especially in the lemma.\n",
    "\n",
    "\n",
    "Top-K: 10 Top-P: 0.3 Temperature: 0.8\n",
    "* Sentence: Wie lange lebst du schon in Stuttgart ?\n",
    "    \n",
    "    * Translation Top-K:  < unk > < pad > . in A < pad > in < unk > \n",
    "    * Translation Top-P:  running old court rocks fire football Men fire floor fire fire fire fire while\n",
    "    * Translation Greedy:  Large long - haired great Dane can be using matching factory ? \n",
    "    * True Translation: How long have you been living in Stuttgart?\n",
    "\n",
    "\n",
    "* Sentence: Eine Gruppe von Menschen steht vor einem Iglu .\n",
    "    \n",
    "    * Translation Top-K:   the < pad > < unk > A < unk > \n",
    "    * Translation Top-P:  posing drink climbing working ready An working smiling climbing climbing workers between climbing while climbing\n",
    "    * Translation Greedy:  A group of people stand in an auditorium . \n",
    "    * True Translation: A group of people standing in front of an igloo .\n",
    "\n",
    "\n",
    "* Sentence: Möglichst ganze Wörter eingeben, die im Artikeltext, insbesondere aber im Lemma vorkommen sollen. \n",
    "    \n",
    "    * Translation Top-K:  < unk > < unk > < pad > \n",
    "    * Translation Top-P:  fishing cross leaning fence front have scarf stage crowded arms left fire fire watching their day stage climbing their appears men climbing\n",
    "    * Translation Greedy:  A female snow athlete with matching belt , who is crouched together in the snowy moment . \n",
    "    * True Translation: If possible, enter whole words that should appear in the article text, but especially in the lemma.\n",
    "\n",
    "\n",
    "Top-K: 20 Top-P: 0.5 Temperature: 0.8\n",
    "* Sentence: Wie lange lebst du schon in Stuttgart ?\n",
    "    \n",
    "    * Translation Top-K:  < unk > A and are the < pad > is man woman < unk > on < pad > of \n",
    "    * Translation Top-P:  car full floor - face computer motorcycle hat motorcycle aged full talking aged lined\n",
    "    * Translation Greedy:  Large long - haired great Dane can be using matching factory ? \n",
    "    * True Translation: How long have you been living in Stuttgart?\n",
    "\n",
    "\n",
    "* Sentence: Eine Gruppe von Menschen steht vor einem Iglu .\n",
    "   \n",
    "    * Translation Top-K:  woman \n",
    "    * Translation Top-P:  ramp who bridge Man Many wave between smiling Men short men soccer woods helmet short\n",
    "    * Translation Greedy:  A group of people stand in an auditorium . \n",
    "    * True Translation: A group of people standing in front of an igloo .\n",
    "\n",
    "\n",
    "* Sentence: Möglichst ganze Wörter eingeben, die im Artikeltext, insbesondere aber im Lemma vorkommen sollen. \n",
    "    \n",
    "    * Translation Top-K:  are and in  man Two < unk > the to man < pad > . Two the < pad > man < unk > woman of  < unk > < pad >\n",
    "    * Translation Top-P:  where leaning cross its glasses others baseball crowded sky fire on fish leaning green crowded walks subway while tall bus adult jumping\n",
    "    * Translation Greedy:  A female snow athlete with matching belt , who is crouched together in the snowy moment . \n",
    "    * True Translation: If possible, enter whole words that should appear in the article text, but especially in the lemma.\n",
    "\n",
    "\n",
    "Top-K: 40 Top-P: 0.7 Temperature: 0.8\n",
    "* Sentence: Wie lange lebst du schon in Stuttgart ?\n",
    "    \n",
    "    * Translation Top-K:  < pad > is man his < unk > black man men at of \n",
    "    * Translation Top-P:  jersey cross glasses leaning motorcycle Men Men jeans while instrument while colorful Men Men\n",
    "    * Translation Greedy:  Large long - haired great Dane can be using matching factory ? \n",
    "    * True Translation: How long have you been living in Stuttgart?\n",
    "\n",
    "\n",
    "* Sentence: Eine Gruppe von Menschen steht vor einem Iglu .\n",
    "    * Translation Top-K:  , shirt girl Two white on < unk > people shirt < pad > young the < unk > \n",
    "    * Translation Top-P:  posing who over down left climbing he snowy down down stairs orange down fire several\n",
    "    * Translation Greedy:  A group of people stand in an auditorium . \n",
    "    * True Translation: A group of people standing in front of an igloo .\n",
    "\n",
    "\n",
    "* Sentence: Möglichst ganze Wörter eingeben, die im Artikeltext, insbesondere aber im Lemma vorkommen sollen. \n",
    "    * Translation Top-K:  < pad > at < unk > young of at  black , blue woman and the of  \n",
    "    * Translation Top-P:  trying stage stage colorful shirts waiting tan playing jump skateboard bench background between she dog men attire while performs basketball crowded climbing\n",
    "    * Translation Greedy:  A female snow athlete with matching belt , who is crouched together in the snowy moment . \n",
    "    * True Translation: If possible, enter whole words that should appear in the article text, but especially in the lemma.\n",
    "\n",
    "\n",
    "Top-K: 10 Top-P: 0.3 Temperature: 1.2\n",
    "* Sentence: Wie lange lebst du schon in Stuttgart ?\n",
    "\n",
    "    * Translation Top-K:  < unk > . \n",
    "    * Translation Top-P:  fishing African rocks leaning colorful other court hat piece Men climbing fire climbing while\n",
    "    * Translation Greedy:  Large long - haired great Dane can be using matching factory ? \n",
    "    * True Translation: How long have you been living in Stuttgart?\n",
    "\n",
    "\n",
    "* Sentence: Eine Gruppe von Menschen steht vor einem Iglu .\n",
    "   \n",
    "    * Translation Top-K:  < pad > < pad > < pad > < pad > \n",
    "    * Translation Top-P:  putting cart toward family sidewalk Man gray gray food climbing sweatshirt paper riding Children window\n",
    "    * Translation Greedy:  A group of people stand in an auditorium . \n",
    "    * True Translation: A group of people standing in front of an igloo .\n",
    "\n",
    "\n",
    "* Sentence: Möglichst ganze Wörter eingeben, die im Artikeltext, insbesondere aber im Lemma vorkommen sollen. \n",
    "   \n",
    "    * Translation Top-K:   in a < unk > < unk > the the . A  A < pad > A the < unk > < unk > . < pad > < pad > a < unk > \n",
    "    * Translation Top-P:  edge shoes fire motorcycle scarf pants cross People cellphone on attire watching both scarf their couple green men men between catch An\n",
    "    * Translation Greedy:  A female snow athlete with matching belt , who is crouched together in the snowy moment . \n",
    "    * True Translation: If possible, enter whole words that should appear in the article text, but especially in the lemma.\n",
    "\n",
    "\n",
    "Top-K: 20 Top-P: 0.5 Temperature: 1.2\n",
    "* Sentence: Wie lange lebst du schon in Stuttgart ?\n",
    " \n",
    "    * Translation Top-K:  < unk > . < pad > to the . A < unk > < unk > < unk > < pad > of < unk > the\n",
    "    * Translation Top-P:  head cross old band line event backpack between stone aged leaning while - paper\n",
    "    * Translation Greedy:  Large long - haired great Dane can be using matching factory ? \n",
    "    * True Translation: How long have you been living in Stuttgart?\n",
    "\n",
    "\n",
    "* Sentence: Eine Gruppe von Menschen steht vor einem Iglu .\n",
    "    \n",
    "    * Translation Top-K:  are , are a a of to a  the a Two \n",
    "    * Translation Top-P:  left sign going going between enjoying suit smiling smiling Men he event left Men while\n",
    "    * Translation Greedy:  A group of people stand in an auditorium . \n",
    "    * True Translation: A group of people standing in front of an igloo .\n",
    "\n",
    "\n",
    "* Sentence: Möglichst ganze Wörter eingeben, die im Artikeltext, insbesondere aber im Lemma vorkommen sollen. \n",
    "    \n",
    "    * Translation Top-K:  \n",
    "    * Translation Top-P:  yard run tree setting does playing table cross dog drinking full colorful jersey This while stage at filled football African African cap\n",
    "    * Translation Greedy:  A female snow athlete with matching belt , who is crouched together in the snowy moment . \n",
    "    * True Translation: If possible, enter whole words that should appear in the article text, but especially in the lemma.\n",
    "\n",
    "\n",
    "Top-K: 40 Top-P: 0.7 Temperature: 1.2\n",
    "* Sentence: Wie lange lebst du schon in Stuttgart ?\n",
    "    \n",
    "    * Translation Top-K:  are .  sitting and A woman man young of standing at boy a\n",
    "    * Translation Top-P:  inside fishing worker fishing making music leaning outdoor other leaning like elderly hat blue\n",
    "    * Translation Greedy:  Large long - haired great Dane can be using matching factory ? \n",
    "    * True Translation: How long have you been living in Stuttgart?\n",
    "\n",
    "\n",
    "* Sentence: Eine Gruppe von Menschen steht vor einem Iglu .\n",
    "    \n",
    "    * Translation Top-K:  sitting man wearing  his < pad > of at < pad > of black the at in black\n",
    "    * Translation Top-P:  building gray hats person doing where floor something This tank camera < unk > orange ground construction\n",
    "    * Translation Greedy:  A group of people stand in an auditorium . \n",
    "    * True Translation: A group of people standing in front of an igloo .\n",
    "\n",
    "\n",
    "* Sentence: Möglichst ganze Wörter eingeben, die im Artikeltext, insbesondere aber im Lemma vorkommen sollen. \n",
    "    \n",
    "    * Translation Top-K:  his . blue A man dog shirt boy < pad > \n",
    "    * Translation Top-P:  driving hands run stage \" outfit their tree track stone both poses fire crowded does takes baby basketball cutting fence tall elderly\n",
    "    * Translation Greedy:  A female snow athlete with matching belt , who is crouched together in the snowy moment . \n",
    "    * True Translation: If possible, enter whole words that should appear in the article text, but especially in the lemma."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute the BLEU score of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu.metrics import BLEU, CHRF, TER\n",
    "bleu = BLEU()\n",
    "predictions_topp = []\n",
    "predictions_topk = []\n",
    "predictions_greedy = []\n",
    "for sentence in sentences:\n",
    "    predictions_topp.append(translate_topp(transformer, sentence, 0.8, 0.8))\n",
    "    predictions_topk.append(translate_topk(transformer, sentence, 60, 0.8))\n",
    "    predictions_greedy.append(translate(transformer, sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BLEU = 0.00 0.0/0.0/0.0/0.0 (BP = 1.000 ratio = 17.000 hyp_len = 51 ref_len = 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.corpus_score(predictions_topp, translations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:\n",
    "* BLEU = 0.00 0.0/0.0/0.0/0.0 (BP = 1.000 ratio = 17.000 hyp_len = 51 ref_len = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BLEU = 0.57 1.5/0.8/0.4/0.2 (BP = 1.000 ratio = 22.333 hyp_len = 67 ref_len = 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.corpus_score(predictions_topk, translations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:\n",
    "* BLEU = 0.57 1.5/0.8/0.4/0.2 (BP = 1.000 ratio = 22.333 hyp_len = 67 ref_len = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BLEU = 0.00 0.0/0.0/0.0/0.0 (BP = 1.000 ratio = 12.667 hyp_len = 38 ref_len = 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.corpus_score(predictions_greedy, translations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: \n",
    "* BLEU = 0.00 0.0/0.0/0.0/0.0 (BP = 1.000 ratio = 12.667 hyp_len = 38 ref_len = 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
